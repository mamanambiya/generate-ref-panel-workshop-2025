name: ğŸ§¬ Federated Imputation Pipeline - Unit Tests

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'workflows/**'
      - 'tasks/**'
      - 'tests/**'
      - 'inputs/**'
      - '.github/workflows/**'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'workflows/**'
      - 'tasks/**'
      - 'tests/**'
      - 'inputs/**'
      - '.github/workflows/**'
  workflow_dispatch:
    inputs:
      test_scope:
        description: 'Test scope to run'
        required: true
        default: 'all'
        type: choice
        options:
        - all
        - extract_region
        - quality_control
        - minimac_conversion
        - complete_pipeline

env:
  CROMWELL_VERSION: "85"
  DOCKER_IMAGE: "mamana/imputation:minimac4-4.1.6"
  JAVA_VERSION: "11"

jobs:
  unit-tests:
    name: ğŸ§ª Unit Tests
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    strategy:
      matrix:
        test_scenario:
          - name: "extract_region"
            workflow: "tests/unit/test_extract_region.wdl"
            config: "tests/inputs/unit_test_config.json"
            description: "Test genomic region extraction"
          - name: "quality_control"
            workflow: "tests/unit/test_quality_control.wdl"
            config: "tests/inputs/qc_unit_test_config.json"
            description: "Test VCF quality control and filtering"
          - name: "minimac_conversion"
            workflow: "tests/unit/test_minimac_conversion.wdl"
            config: "tests/inputs/minimac_unit_test_config.json"
            description: "Test MSAV format conversion"
          - name: "complete_pipeline"
            workflow: "tests/unit/test_complete_pipeline.wdl"
            config: "tests/inputs/complete_pipeline_test_config.json"
            description: "Test complete pipeline integration"
      fail-fast: false

    steps:
    - name: ğŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: â˜• Set up Java ${{ env.JAVA_VERSION }}
      uses: actions/setup-java@v4
      with:
        distribution: 'temurin'
        java-version: ${{ env.JAVA_VERSION }}

    - name: ğŸ³ Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: ğŸ“¦ Cache Cromwell
      id: cache-cromwell
      uses: actions/cache@v4
      with:
        path: cromwell.jar
        key: cromwell-${{ env.CROMWELL_VERSION }}

    - name: â¬‡ï¸ Download Cromwell
      if: steps.cache-cromwell.outputs.cache-hit != 'true'
      run: |
        echo "ğŸ“¥ Downloading Cromwell v${{ env.CROMWELL_VERSION }}..."
        curl -L -o cromwell.jar \
          "https://github.com/broadinstitute/cromwell/releases/download/${{ env.CROMWELL_VERSION }}/cromwell-${{ env.CROMWELL_VERSION }}.jar"
        echo "âœ… Cromwell downloaded successfully"

    - name: ğŸ” Verify Cromwell Installation
      run: |
        ls -la cromwell.jar
        java -jar cromwell.jar --version

    - name: ğŸ³ Pull Docker Image
      run: |
        echo "ğŸ“¥ Pulling Docker image: ${{ env.DOCKER_IMAGE }}"
        docker pull --platform linux/amd64 ${{ env.DOCKER_IMAGE }}
        echo "âœ… Docker image pulled successfully"

    - name: ğŸ” Verify Docker Image
      run: |
        echo "ğŸ” Verifying Docker image contents..."
        docker run --rm --platform linux/amd64 ${{ env.DOCKER_IMAGE }} which bcftools
        docker run --rm --platform linux/amd64 ${{ env.DOCKER_IMAGE }} which minimac4
        docker run --rm --platform linux/amd64 ${{ env.DOCKER_IMAGE }} bcftools --version | head -3
        docker run --rm --platform linux/amd64 ${{ env.DOCKER_IMAGE }} minimac4 --help | head -5

    - name: ğŸ“‚ Prepare Test Environment
      run: |
        echo "ğŸ“‚ Setting up test environment..."
        mkdir -p test_results/github_actions
        echo "Current working directory: $(pwd)"
        echo "Available files:"
        ls -la tests/
        echo "Test data:"
        ls -la tests/test_*

    - name: ğŸ”§ Update Input Configurations for GitHub Actions
      run: |
        echo "ğŸ”§ Updating input configurations with absolute paths..."
        
        # Get absolute path to test data
        TEST_VCF_PATH="$(pwd)/tests/test_chr22_region_bgzip.vcf.gz"
        
        # Update all input configuration files
        for config_file in tests/inputs/*.json; do
          echo "Updating $config_file..."
          # Create backup
          cp "$config_file" "$config_file.backup"
          
          # Update path in JSON file
          sed -i "s|/Users/mamana/projects-uct/afrigen-d/ga4gh_hackathon_2025/prepare_minimac4_data/tests/test_chr22_region_bgzip.vcf.gz|$TEST_VCF_PATH|g" "$config_file"
          
          echo "Updated configuration:"
          cat "$config_file"
          echo "---"
        done

    - name: ğŸ§ª Run Unit Test - ${{ matrix.test_scenario.name }}
      run: |
        echo "ğŸ§ª Running ${{ matrix.test_scenario.name }} test..."
        echo "Description: ${{ matrix.test_scenario.description }}"
        echo "Workflow: ${{ matrix.test_scenario.workflow }}"
        echo "Config: ${{ matrix.test_scenario.config }}"
        echo ""
        
        # Run the test
        echo "Starting Cromwell execution..."
        timeout 45m java -jar cromwell.jar run \
          "${{ matrix.test_scenario.workflow }}" \
          -i "${{ matrix.test_scenario.config }}" \
          > "test_results/github_actions/${{ matrix.test_scenario.name }}_output.log" 2>&1
        
        echo "âœ… ${{ matrix.test_scenario.name }} test completed successfully"

    - name: ğŸ“Š Extract Test Results
      if: always()
      run: |
        echo "ğŸ“Š Extracting test results for ${{ matrix.test_scenario.name }}..."
        
        # Find validation report
        VALIDATION_REPORT=$(find cromwell-executions -name "*validation_report.txt" -type f | head -1)
        
        if [[ -n "$VALIDATION_REPORT" && -f "$VALIDATION_REPORT" ]]; then
          echo "ğŸ“„ Found validation report: $VALIDATION_REPORT"
          cp "$VALIDATION_REPORT" "test_results/github_actions/${{ matrix.test_scenario.name }}_validation_report.txt"
          
          echo "ğŸ“‹ Validation Report Contents:"
          echo "==============================="
          cat "$VALIDATION_REPORT"
          echo "==============================="
          
          # Check if test passed
          if grep -q "TEST PASSED\|ALL TESTS PASSED" "$VALIDATION_REPORT"; then
            echo "âœ… ${{ matrix.test_scenario.name }}: PASSED"
            echo "PASSED" > "test_results/github_actions/${{ matrix.test_scenario.name }}_result.txt"
          else
            echo "âŒ ${{ matrix.test_scenario.name }}: FAILED"
            echo "FAILED" > "test_results/github_actions/${{ matrix.test_scenario.name }}_result.txt"
          fi
        else
          echo "âš ï¸ No validation report found"
          echo "UNKNOWN" > "test_results/github_actions/${{ matrix.test_scenario.name }}_result.txt"
        fi
        
        # Extract key metrics from Cromwell output
        echo ""
        echo "ğŸ“ˆ Cromwell Execution Summary:"
        echo "=============================="
        if [[ -f "test_results/github_actions/${{ matrix.test_scenario.name }}_output.log" ]]; then
          grep -E "(WorkflowSucceeded|WorkflowFailed|Final Outputs)" "test_results/github_actions/${{ matrix.test_scenario.name }}_output.log" || echo "No summary found"
        fi

    - name: ğŸ“¤ Upload Test Artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-results-${{ matrix.test_scenario.name }}
        path: |
          test_results/github_actions/${{ matrix.test_scenario.name }}_*.txt
          test_results/github_actions/${{ matrix.test_scenario.name }}_*.log
        retention-days: 30

    - name: ğŸ§¹ Cleanup Test Execution
      if: always()
      run: |
        echo "ğŸ§¹ Cleaning up test execution files..."
        # Keep validation reports but clean up large execution directories
        find cromwell-executions -type d -name "call-*" -exec rm -rf {} + 2>/dev/null || true
        find cromwell-executions -name "*.log" -size +10M -delete 2>/dev/null || true
        echo "âœ… Cleanup completed"

  test-summary:
    name: ğŸ“Š Test Summary
    needs: unit-tests
    runs-on: ubuntu-latest
    if: always()
    
    steps:
    - name: ğŸ“¥ Download All Test Results
      uses: actions/download-artifact@v4
      with:
        path: all_test_results
        pattern: test-results-*

    - name: ğŸ“Š Generate Test Summary
      run: |
        echo "ğŸ“Š Generating comprehensive test summary..."
        
        TOTAL_TESTS=0
        PASSED_TESTS=0
        FAILED_TESTS=0
        UNKNOWN_TESTS=0
        
        echo "# ğŸ§¬ Federated Imputation Pipeline - Test Results" > test_summary.md
        echo "## GA4GH Hackathon 2025 - African Genomics Team" >> test_summary.md
        echo "" >> test_summary.md
        echo "**Test Run Date:** $(date -u)" >> test_summary.md
        echo "**GitHub Action:** ${{ github.workflow }}" >> test_summary.md
        echo "**Commit:** ${{ github.sha }}" >> test_summary.md
        echo "**Branch:** ${{ github.ref_name }}" >> test_summary.md
        echo "" >> test_summary.md
        
        echo "## ğŸ“‹ Test Results Summary" >> test_summary.md
        echo "" >> test_summary.md
        echo "| Test Name | Status | Description |" >> test_summary.md
        echo "|-----------|--------|-------------|" >> test_summary.md
        
        # Process each test result
        for result_dir in all_test_results/test-results-*; do
          if [[ -d "$result_dir" ]]; then
            test_name=$(basename "$result_dir" | sed 's/test-results-//')
            result_file="$result_dir/${test_name}_result.txt"
            
            TOTAL_TESTS=$((TOTAL_TESTS + 1))
            
            if [[ -f "$result_file" ]]; then
              result=$(cat "$result_file")
              case "$result" in
                "PASSED")
                  echo "| $test_name | âœ… PASSED | Test completed successfully |" >> test_summary.md
                  PASSED_TESTS=$((PASSED_TESTS + 1))
                  ;;
                "FAILED")
                  echo "| $test_name | âŒ FAILED | Test encountered errors |" >> test_summary.md
                  FAILED_TESTS=$((FAILED_TESTS + 1))
                  ;;
                *)
                  echo "| $test_name | âš ï¸ UNKNOWN | Test status unclear |" >> test_summary.md
                  UNKNOWN_TESTS=$((UNKNOWN_TESTS + 1))
                  ;;
              esac
            else
              echo "| $test_name | âš ï¸ NO RESULT | Result file not found |" >> test_summary.md
              UNKNOWN_TESTS=$((UNKNOWN_TESTS + 1))
            fi
          fi
        done
        
        echo "" >> test_summary.md
        echo "## ğŸ“ˆ Statistics" >> test_summary.md
        echo "" >> test_summary.md
        echo "- **Total Tests:** $TOTAL_TESTS" >> test_summary.md
        echo "- **Passed:** $PASSED_TESTS âœ…" >> test_summary.md
        echo "- **Failed:** $FAILED_TESTS âŒ" >> test_summary.md
        echo "- **Unknown:** $UNKNOWN_TESTS âš ï¸" >> test_summary.md
        
        if [[ $TOTAL_TESTS -gt 0 ]]; then
          SUCCESS_RATE=$(echo "scale=1; $PASSED_TESTS * 100 / $TOTAL_TESTS" | bc)
          echo "- **Success Rate:** ${SUCCESS_RATE}% ğŸ“Š" >> test_summary.md
        fi
        
        echo "" >> test_summary.md
        
        # Overall status
        if [[ $FAILED_TESTS -eq 0 && $UNKNOWN_TESTS -eq 0 && $PASSED_TESTS -gt 0 ]]; then
          echo "## ğŸ‰ Overall Result: SUCCESS" >> test_summary.md
          echo "" >> test_summary.md
          echo "All unit tests passed successfully! The federated imputation pipeline is ready for production use." >> test_summary.md
          echo "TEST_STATUS=success" >> $GITHUB_ENV
        elif [[ $FAILED_TESTS -gt 0 ]]; then
          echo "## âŒ Overall Result: FAILURE" >> test_summary.md
          echo "" >> test_summary.md
          echo "Some unit tests failed. Please review the detailed test reports and fix any issues before deployment." >> test_summary.md
          echo "TEST_STATUS=failure" >> $GITHUB_ENV
        else
          echo "## âš ï¸ Overall Result: INCOMPLETE" >> test_summary.md
          echo "" >> test_summary.md
          echo "Test execution was incomplete or inconclusive. Please review the test logs for more information." >> test_summary.md
          echo "TEST_STATUS=incomplete" >> $GITHUB_ENV
        fi
        
        # Add detailed validation reports
        echo "" >> test_summary.md
        echo "## ğŸ“„ Detailed Test Reports" >> test_summary.md
        echo "" >> test_summary.md
        
        for result_dir in all_test_results/test-results-*; do
          if [[ -d "$result_dir" ]]; then
            test_name=$(basename "$result_dir" | sed 's/test-results-//')
            validation_file="$result_dir/${test_name}_validation_report.txt"
            
            if [[ -f "$validation_file" ]]; then
              echo "### $test_name Test Details" >> test_summary.md
              echo "" >> test_summary.md
              echo '```' >> test_summary.md
              cat "$validation_file" >> test_summary.md
              echo '```' >> test_summary.md
              echo "" >> test_summary.md
            fi
          fi
        done
        
        echo "ğŸ“„ Test summary generated successfully"
        echo ""
        echo "=== TEST SUMMARY ==="
        cat test_summary.md

    - name: ğŸ“¤ Upload Test Summary
      uses: actions/upload-artifact@v4
      with:
        name: test-summary
        path: test_summary.md
        retention-days: 90

    - name: ğŸ’¬ Comment Test Results on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const testSummary = fs.readFileSync('test_summary.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: testSummary
          });

    - name: âœ… Set Final Status
      run: |
        echo "Final test status: $TEST_STATUS"
        
        if [[ "$TEST_STATUS" == "failure" ]]; then
          echo "âŒ Unit tests failed - blocking merge"
          exit 1
        elif [[ "$TEST_STATUS" == "incomplete" ]]; then
          echo "âš ï¸ Unit tests incomplete - review required"
          exit 1
        else
          echo "âœ… All unit tests passed successfully!"
          exit 0
        fi 